{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop, Train, Optimize and Deploy Scikit-Learn Random Forest\n",
    "\n",
    "* Doc https://sagemaker.readthedocs.io/en/stable/using_sklearn.html\n",
    "* SDK https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html\n",
    "* boto3 https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#client\n",
    "\n",
    "In this notebook we show how to use Amazon SageMaker to develop, train, tune and deploy a Scikit-Learn based ML model (Random Forest). More info on Scikit-Learn can be found here https://scikit-learn.org/stable/index.html. We use the Boston Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/datasets/index.html#boston-dataset\n",
    "\n",
    "\n",
    "More info on the dataset:\n",
    "\n",
    "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978. Used in Belsley, Kuh & Welsch, 'Regression diagnostics ...', Wiley, 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter.\n",
    "\n",
    "The Boston house-price data has been used in many machine learning papers that address regression problems.\n",
    "References\n",
    "\n",
    " * Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
    " * Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "**This sample is provided for demonstration purposes, make sure to conduct appropriate testing if derivating this code for your own use-cases!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "prefix = 'sklearn-demo'\n",
    "print(\"Using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "We load a dataset from sklearn, split it and send it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the Boston housing dataset\n",
    "df = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.data, df.target, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "df_train = pd.DataFrame(X_train, columns=df.feature_names)\n",
    "df_train[\"target\"] = y_train\n",
    "\n",
    "df_test = pd.DataFrame(X_test, columns=df.feature_names)\n",
    "df_test[\"target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = df_train.hist(bins=30, sharey=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data\n",
    "df_train.to_csv(\"./data/boston_train.csv\")\n",
    "df_test.to_csv(\"./data/boston_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "train_path = sess.upload_data(\n",
    "    path=\"./data/boston_train.csv\", bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "test_path = sess.upload_data(\n",
    "    path=\"./data/boston_test.csv\", bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have a more involved preprocessing step, you can use [SageMaker Processing](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html). Amazon SageMaker Processing Jobs. \n",
    "\n",
    "With Processing, you can use a simplified, managed experience on SageMaker to run your data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation. \n",
    "\n",
    "\n",
    "For a sample notebook that shows how to run scikit-learn scripts to perform data preprocessing and model training and evaluation with the SageMaker Python SDK for Processing, see [scikit-learn Processing](https://github.com/aws/amazon-sagemaker-examples/tree/master/sagemaker_processing/scikit_learn_data_processing_and_model_evaluation). This notebook also shows how to use your own custom container to run processing workloads with your Python libraries and other specific dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a *Script Mode* script\n",
    "The below script contains both training and inference functionality and can run both in SageMaker Training hardware or locally (desktop, SageMaker notebook, on prem, etc). Detailed guidance here https://sagemaker.readthedocs.io/en/stable/using_sklearn.html#preparing-the-scikit-learn-training-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"extracting arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"boston_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"boston_test.csv\")\n",
    "    parser.add_argument(\n",
    "        \"--features\", type=str\n",
    "    )  # in this script we ask user to explicitly name features\n",
    "    parser.add_argument(\n",
    "        \"--target\", type=str\n",
    "    )  # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"reading data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"building training and testing datasets\")\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    # train\n",
    "    print(\"training model\")\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators, min_samples_leaf=args.min_samples_leaf, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print abs error\n",
    "    print(\"validating model\")\n",
    "    abs_err = np.abs(model.predict(X_test) - y_test)\n",
    "\n",
    "    # print couple perf metrics\n",
    "    for q in [10, 50, 90]:\n",
    "        print(\"AE-at-\" + str(q) + \"th-percentile: \" + str(np.percentile(a=abs_err, q=q)))\n",
    "\n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(\"model persisted at \" + path)\n",
    "    print(args.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training\n",
    "Script arguments allows us to remove from the script any SageMaker-specific configuration, and run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model\n",
    "! python script.py --n-estimators 100 \\\n",
    "                   --min-samples-leaf 2 \\\n",
    "                   --model-dir ./model \\\n",
    "                   --train ./data/ \\\n",
    "                   --test ./data/ \\\n",
    "                   --features 'CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT' \\\n",
    "                   --target target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with Spot Instances using the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Estimator from the SageMaker Python SDK\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "\n",
    "# configure spot training\n",
    "use_spot_instances = True\n",
    "max_run = 3600\n",
    "max_wait = 7200 if use_spot_instances else None\n",
    "checkpoint_s3_uri = (f's3://{bucket}/sagemaker/checkpoints/' if use_spot_instances\n",
    "                      else None)\n",
    "print(checkpoint_s3_uri)\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"features\": \"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\n",
    "        \"target\": \"target\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"rf-scikit\",\n",
    "    metric_definitions=[{\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n",
    "    hyperparameters=hyperparameters,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({\"train\": train_path, \"test\": test_path}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a tuning job with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the Hyperparameter Tuner\n",
    "from sagemaker.tuner import IntegerParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    \"n-estimators\": IntegerParameter(20, 100),\n",
    "    \"min-samples-leaf\": IntegerParameter(2, 6),\n",
    "}\n",
    "\n",
    "# create Optimizer\n",
    "my_tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=sklearn_estimator,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    strategy=\"Bayesian\",\n",
    "    base_tuning_job_name=\"RF-tuner\",\n",
    "    objective_type=\"Minimize\",\n",
    "    objective_metric_name=\"median-AE\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"}\n",
    "    ],  # extract tracked metric from logs with regexp\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tuner.fit({\"train\": train_path, \"test\": test_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuner results in a df\n",
    "results = my_tuner.analytics().dataframe()\n",
    "while results.empty:\n",
    "    time.sleep(1)\n",
    "    results = my_tuner.analytics().dataframe()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best estimator from tuning job\n",
    "best_job_est = my_tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform\n",
    "\n",
    "Use batch transform when you need to do the following:\n",
    "\n",
    "* Preprocess datasets to remove noise or bias that interferes with training or inference from your dataset.\n",
    "* Get inferences from large datasets.\n",
    "* Run inference when you don't need a persistent endpoint.\n",
    "* Associate input records with inferences to assist the interpretation of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = f's3://{bucket}/{prefix}/transform/'\n",
    "\n",
    "sm_transformer = best_job_est.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    accept = 'text/csv',\n",
    "    output_path= batch_output\n",
    ")\n",
    "\n",
    "sm_transformer.transform(test_path, content_type='text/csv',\n",
    "                         split_type='Line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the batch transform job is complete, SageMaker creates the test.csv.out prediction data saved in the batch_output path, which should be in the following format: s3://sagemaker-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir output\n",
    "! aws s3 cp {batch_output} ./output --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to a real-time endpoint - optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy with Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `Estimator` could be deployed directly after training, with an `Estimator.deploy()` but here we showcase the more extensive process of creating a model from s3 artifacts, that could be used to deploy a model that was trained in a different session or even out of SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "# artifact = sm_boto3.describe_training_job(\n",
    "#     TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    "# )[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "# print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "# model = SKLearnModel(\n",
    "#     model_data=artifact,\n",
    "#     role=get_execution_role(),\n",
    "#     entry_point=\"script.py\",\n",
    "#     framework_version=FRAMEWORK_VERSION,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = model.deploy(instance_type=\"ml.c5.large\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the SKLearnPredictor does the serialization from pandas for us\n",
    "# y_pred = predictor.predict(testX[data.feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# y_true = df_test['target'].to_list()\n",
    "# print(f'Mean Absolute Error: {mean_absolute_error(y_true, y_pred)} \\nR-squared: {r2_score(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget to delete the endpoint !\n",
    "\n",
    "If you deployed an endpoint and are ready to be done with this notebook, please run the cell below. This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_boto3.delete_endpoint(EndpointName=predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions\n",
    "\n",
    "There are several ways of extending what we have done in this notebook including:\n",
    "- Adding SageMaker Clarify to detect bias in data and model, and explain model behaviour\n",
    "- Use SageMaker Processing for preprocessing and model evaluation jobs\n",
    "- Use SageMaker Pipelines to compose, manage, and reuse your ML workflows\n",
    "\n",
    "\n",
    "Regardless of additional complexity, similar principles described in this notebook are likely apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
